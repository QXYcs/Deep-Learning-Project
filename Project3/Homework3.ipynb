{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frame the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function                  \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import sys\n",
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"sonnet.txt\"\n",
    "#read the file and make all chracaters lowercase\n",
    "text = open(filename).read().lower() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# print(char_indices) #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 38\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)   \n",
    "print(x.shape[1],x.shape[2])\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool) \n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "###Using LSTM\n",
    "model.add(LSTM(128, input_shape=(x.shape[1], x.shape[2])))\n",
    "###Using advanced Activations\n",
    "PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Train the model and predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 30s 935us/step - loss: 2.9819\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 29s 911us/step - loss: 2.5777\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 28s 863us/step - loss: 2.3539\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 28s 874us/step - loss: 2.2447\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 26s 808us/step - loss: 2.1645\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 26s 811us/step - loss: 2.1016\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 27s 860us/step - loss: 2.0413\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 28s 865us/step - loss: 1.9879\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 28s 873us/step - loss: 1.9474\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 28s 874us/step - loss: 1.9071\n",
      "\n",
      "Iteration 1\n",
      "he sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the s\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 28s 886us/step - loss: 1.8718\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 28s 877us/step - loss: 1.8437\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 30s 932us/step - loss: 1.8131\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 28s 887us/step - loss: 1.7870\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 28s 882us/step - loss: 1.7580\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 28s 877us/step - loss: 1.7328\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 28s 878us/step - loss: 1.7088\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 28s 880us/step - loss: 1.6859\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 28s 879us/step - loss: 1.6601\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 28s 886us/step - loss: 1.6362\n",
      "\n",
      "Iteration 2\n",
      "the surmer sore the stall the will the will the store thee,\n",
      "and the stall the will the will the will the store,\n",
      "and the stall the will the will the will the store,\n",
      "and the stall the will the will the will the store,\n",
      "and the stall the will the will the will the store,\n",
      "and the stall the will the will the will the store,\n",
      "and the stall the will the will the will the store,\n",
      "and the stall the will the w\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 28s 890us/step - loss: 1.6157\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 29s 903us/step - loss: 1.5935\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 29s 901us/step - loss: 1.5706\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 28s 888us/step - loss: 1.5483\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 28s 890us/step - loss: 1.5236\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 28s 893us/step - loss: 1.5006\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 28s 891us/step - loss: 1.4762\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 28s 893us/step - loss: 1.4484\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 29s 898us/step - loss: 1.4236\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 28s 891us/step - loss: 1.3971\n",
      "\n",
      "Iteration 3\n",
      "se then the love to thee,\n",
      "and thou are the surmer sumber of the dear;\n",
      "thy beauty that the stall the will me doth lie,\n",
      "that the wint of then the wind of the dear;\n",
      "that the will me beauty shall the will me so ling,\n",
      "and that thee thou art the will me belofe thee\n",
      "though thy still summer surment fare,\n",
      "  and the stall the will me beauty shall,\n",
      "and that thee thou art the will me doth stowe,\n",
      "  and thee th\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 29s 903us/step - loss: 1.3743\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 28s 889us/step - loss: 1.3401\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 28s 875us/step - loss: 1.3114\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 28s 871us/step - loss: 1.2830\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 28s 892us/step - loss: 1.2538\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 27s 861us/step - loss: 1.2264\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 26s 827us/step - loss: 1.1956\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 28s 881us/step - loss: 1.1640\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 29s 900us/step - loss: 1.1360\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 29s 908us/step - loss: 1.1055\n",
      "\n",
      "Iteration 4\n",
      "and their stall flow,\n",
      "and in the world exes beauty so dost do not,\n",
      "  and to the world deth thou art for thy strat,\n",
      "for it a to the with with sore thee wort doth dear;\n",
      "the beturis doth the grove the love to muserest,\n",
      "and then i an the beauty shall heaven the loods\n",
      "the worsh so forter'd of the with with of stome,\n",
      "and the with with sore the worst of thy love to make sene,\n",
      "  and thee is the world exco\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 26s 816us/step - loss: 1.0716\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 27s 849us/step - loss: 1.0420\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 29s 901us/step - loss: 1.0127\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 26s 811us/step - loss: 0.9903\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 28s 866us/step - loss: 0.9547\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 27s 856us/step - loss: 0.9277\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 27s 857us/step - loss: 0.8979\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 25s 789us/step - loss: 0.8765\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 28s 871us/step - loss: 0.8410\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 24s 747us/step - loss: 0.8186\n",
      "\n",
      "Iteration 5\n",
      " they,\n",
      "the be the berie but were beauty comety fromm.\n",
      "\n",
      "xii\n",
      "\n",
      "not now some bes brail a you a faist in maken;\n",
      "  the earth as all the see the offead dear\n",
      "mate i with the farth so forth'd wrome to beare;\n",
      "  and they sors fan see thoughts my soul,\n",
      "what the with with shall the woord cruet,\n",
      "the reppls is not deat head to cremmment\n",
      "and ere what it bet berie;\n",
      "  lerse but were your heart kind and thee.\n",
      "thy be\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 23s 721us/step - loss: 0.7955\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 23s 721us/step - loss: 0.7688\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 27s 834us/step - loss: 0.7446\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 26s 803us/step - loss: 0.7194\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 25s 796us/step - loss: 0.6984\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 25s 785us/step - loss: 0.6880\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 26s 804us/step - loss: 0.6606\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 26s 801us/step - loss: 0.6466\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 26s 818us/step - loss: 0.6238\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 24s 768us/step - loss: 0.60791s \n",
      "\n",
      "Iteration 6\n",
      " to all my some shall for sorr,\n",
      "and thou wint of your shalt cone of no lone,\n",
      "so have shall will place but in the blood;\n",
      "though wrot not not no grace of the crows,\n",
      "and the be their sumber subsent farth while eres, \n",
      "but not in the bleations of the heart,\n",
      "  and heself kive whente decpoud from thee,\n",
      "  in i prenter his sty stave soults, on me the wrars you shall,\n",
      "and and share that i fone a torlomn\n",
      "the\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 25s 773us/step - loss: 0.5893\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 25s 795us/step - loss: 0.5691\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 26s 802us/step - loss: 0.5534\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 25s 779us/step - loss: 0.5413\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31884/31884 [==============================] - 30s 930us/step - loss: 0.5213\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 29s 922us/step - loss: 0.5208\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 25s 772us/step - loss: 0.4969\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 27s 838us/step - loss: 0.4850\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 25s 769us/step - loss: 0.4721\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 23s 716us/step - loss: 0.4564\n",
      "\n",
      "Iteration 7\n",
      "therectile excerid mercounow cay,\n",
      "  my slet, the urneratt and hast in plessing deeast\n",
      "of sweer the butiegh rowged to corrtye\n",
      "if fout farthys of sublest which thy sull\n",
      "to be to budion sumper graching?\n",
      "which thoughtsussionss thy spood achull wert,\n",
      "why cay my dear lessest of see be thee,\n",
      "and you mays you seev'st not excoom line.\n",
      "  so shall me but not some to have wall met\n",
      "as oll, my somess fair, what\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 25s 797us/step - loss: 0.4493\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 26s 822us/step - loss: 0.4353\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 22s 689us/step - loss: 0.4236\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 24s 754us/step - loss: 0.4133\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 29s 897us/step - loss: 0.4038\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 27s 848us/step - loss: 0.4333\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 27s 856us/step - loss: 0.3928\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 29s 916us/step - loss: 0.3899\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 26s 809us/step - loss: 0.3689\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 26s 821us/step - loss: 0.3846\n",
      "\n",
      "Iteration 8\n",
      " earss of eeser's peas\n",
      "no shore the foor and bairt chould mee, for me morn of mire\n",
      "that they sing and wot doth shoul happine\n",
      "and to mase, and with the but heart dight?\n",
      "arr mant of mast i and have what when it thon from ment\n",
      "the ears to heart, and ther form to man sair,\n",
      "and placue of the beart, browes of they slow so dull,\n",
      "and to mo thus mast in place of my.\n",
      "\n",
      "liii\n",
      "\n",
      "if not time, and as the to mander\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 24s 762us/step - loss: 0.3560\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 26s 805us/step - loss: 0.4036\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 27s 860us/step - loss: 0.3638\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 25s 773us/step - loss: 0.3222\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 27s 835us/step - loss: 0.3272\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 29s 900us/step - loss: 0.3170\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 29s 908us/step - loss: 0.3180\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - ETA: 0s - loss: 0.320 - 25s 781us/step - loss: 0.3207\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 29s 911us/step - loss: 0.3273\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 29s 918us/step - loss: 0.3103\n",
      "\n",
      "Iteration 9\n",
      "now the famsers oundis\n",
      "with the bring exce moth preever chapes be;\n",
      "meeng beaster and hes beauty love age dey:\n",
      "is though suns sightly my might my mine,\n",
      "  and cane the sempor with which sud i nothol'd herre,\n",
      "but in the briegns shest barule but hein stow'd,\n",
      "which have shade patser beaute thee to doe.\n",
      "\n",
      "cxxxiii\n",
      "\n",
      "if thou, for thy falll-sourmes sainte? where of yet,\n",
      "  and is the wert which for lose ano h\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 29s 919us/step - loss: 0.3220\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 27s 857us/step - loss: 0.3059\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 31s 982us/step - loss: 0.2804\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 31s 959us/step - loss: 0.2954\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 32s 998us/step - loss: 0.3234\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 32s 1ms/step - loss: 0.3260\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 32s 990us/step - loss: 0.2740\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 27s 858us/step - loss: 0.2571\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 26s 807us/step - loss: 0.23441s - \n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 27s 837us/step - loss: 0.2271\n",
      "\n",
      "Iteration 10\n",
      "r lov'd is plorid.\n",
      "\n",
      "xxiv\n",
      "\n",
      "no gair fright of meser of worcken de,\n",
      "but in thes, but where call the sweet to farth sore dear; to come,\n",
      "thou conss in bliching she then would being bear.\n",
      "\n",
      "lv\n",
      "\n",
      "the hawe morl wel your proford twe chearire,\n",
      "whill of your fair this of thou sun's to mimeress allemengs;\n",
      "  that as fair from thou ar faisuress deeds.\n",
      "het me thom the seemmann of then spore ald me mort to mee,\n",
      "  a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Using Early Stopping\n",
    "best_weights_filepath = './best_weights.hdf5' \n",
    "                                            \n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                              patience = 3) \n",
    "\n",
    "SaveBestWeights = keras.callbacks.ModelCheckpoint(best_weights_filepath,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True)\n",
    "for iteration in range(1, 11):\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=10)\n",
    "    \n",
    "    print('\\nIteration', iteration)\n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]      \n",
    "        next_index = np.argmax(preds)                   \n",
    "        next_char = indices_char[next_index]             \n",
    "        sentence = sentence[1:] + next_char              \n",
    "\n",
    "        sys.stdout.write(next_char)                \n",
    "        sys.stdout.flush()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
